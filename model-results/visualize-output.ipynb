{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pickle\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "USER = \"leila\"\n",
    "CHECKPOINT_NAME = f\"test_3_samp_5_epoch.ckpt\"\n",
    "CHECKPOINT_PATH = f\"/autofs/space/celer_001/users/{USER}/ckpt/{CHECKPOINT_NAME}\"\n",
    "TRACER = \"pbr28\"\n",
    "FINAL_DATA_PATH_FOR_MODEL = f\"/autofs/space/celer_001/users/{USER}/data/{TRACER}\"\n",
    "FILTERED_PATIENT_LIST_WITH_GT = f\"/autofs/space/celer_001/users/{USER}/working_{TRACER}/pickles/unfiltered_patient_list.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list_object(filtered_patient_list_path, input_data_root, trial_time=\"3600-180\", recon_alg=\"OP\"):\n",
    "    list_dataset_train = []\n",
    "\n",
    "    with open(filtered_patient_list_path, \"rb\") as f:\n",
    "        gt_patient_list = pickle.load(f)\n",
    "\n",
    "    current_patients = [pat.split(\"/\")[-2]  for pat in glob.glob(f\"{input_data_root}/**/\")]\n",
    "\n",
    "    for patient in gt_patient_list:\n",
    "        if patient in current_patients:\n",
    "            list_dataset_train.append({\n",
    "            'input' : [ f\"{input_data_root}/{patient}/pet_nifti/{trial_time}_{recon_alg}.nii.gz\", \n",
    "            f\"{input_data_root}/{patient}/mr_nifti/t1_img_registered.nii.gz\"\n",
    "            ],\n",
    "            'gt':f\"{input_data_root}/{patient}/pet_nifti/gt_recon.nii.gz\"\n",
    "            })\n",
    "\n",
    "    return list_dataset_train\n",
    "\n",
    "def prepare_data_from_nifti(path_load, list_augments=[], scale_by_norm=True):\n",
    "\t# get nifti\n",
    "\tnib_load = nib.load(path_load)\n",
    "\tprint(nib_load.header)\n",
    "\t# get data\n",
    "\tdata_load = np.squeeze(nib_load.get_fdata())\n",
    "\t# transpose to slice*x*y*channel\n",
    "\tprint(\"SHAPE\", data_load.shape)\n",
    "\tdata_load = np.transpose(data_load[:,:,:,np.newaxis], [2,0,1,3])\n",
    "\t# scale\n",
    "\tif scale_by_norm:\n",
    "\t\t#df = data_load.flatten()\n",
    "\t\t#norm_factor = np.linalg.norm(df)\n",
    "\t\tdata_load = data_load / np.linalg.norm(data_load.flatten())\n",
    "\t# finish loading data\n",
    "\tprint('loaded from {0}, data size {1} (sample, x, y, channel)'.format(path_load, data_load.shape))    \n",
    "\t\n",
    "\t# augmentation\n",
    "\tif len(list_augments)>0:\n",
    "\t\tprint('data augmentation')\n",
    "\t\tlist_data = []\n",
    "\t\tfor augment in list_augments:\n",
    "\t\t\tprint(augment)\n",
    "\t\t\t# data_augmented = augment_data(data_load, axis_xy = [1,2], augment = augment)\n",
    "\t\t\t# list_data.append(data_augmented.reshape(data_load.shape))\n",
    "\t\t# data_load = np.concatenate(list_data, axis = 0)\n",
    "\treturn data_load #, norm_factor # KC 20171018\n",
    "\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# use skimage metrics\n",
    "from skimage.metrics import mean_squared_error, normalized_root_mse, peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "# psnr with TF\n",
    "try:\n",
    "\tfrom tensorflow.python.keras import backend as K\n",
    "\tfrom tensorflow.compat.v1 import log as tf_log\n",
    "\tfrom tensorflow.compat.v1 import constant as tf_constant\n",
    "\timport tensorflow.compat.v1 as tf\n",
    "except:\n",
    "\tprint('import keras and tf backend failed')\n",
    "\n",
    "def PSNRLoss(y_true, y_pred):\n",
    "\t\"\"\"\n",
    "\tPSNR is Peek Signal to Noise Ratio, which is similar to mean squared error.\n",
    "\n",
    "\tIt can be calculated as\n",
    "\tPSNR = 20 * log10(MAXp) - 10 * log10(MSE)\n",
    "\n",
    "\tWhen providing an unscaled input, MAXp = 255. Therefore 20 * log10(255)== 48.1308036087.\n",
    "\tHowever, since we are scaling our input, MAXp = 1. Therefore 20 * log10(1) = 0.\n",
    "\tThus we remove that component completely and only compute the remaining MSE component.\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\t#use theano\n",
    "\t\treturn 20.*np.log10(K.max(y_true)) -10. * np.log10(K.mean(K.square(y_pred - y_true)))\n",
    "\texcept:\n",
    "\t\tdenominator = tf_log(tf_constant(10.0))\n",
    "\t\treturn 20.*tf_log(K.max(y_true)) / denominator -10. * tf_log(K.mean(K.square(y_pred - y_true))) / denominator\n",
    "\treturn 0\n",
    "\n",
    "#get error metrics, for psnr, ssimr, rmse, score_ismrm\n",
    "def getErrorMetrics(im_pred, im_gt, mask = None):\n",
    "\t# flatten array\n",
    "\tim_pred = np.array(im_pred).astype(np.float).flatten()\n",
    "\tim_gt = np.array(im_gt).astype(np.float).flatten()\n",
    "\tif mask is not None:\n",
    "\t\tmask = np.array(mask).astype(np.float).flatten()\n",
    "\t\tim_pred = im_pred[mask>0]\n",
    "\t\tim_gt = im_gt[mask>0]\n",
    "\tmask=np.abs(im_gt.flatten())>0\n",
    "\n",
    "\t# check dimension\n",
    "\tassert(im_pred.flatten().shape==im_gt.flatten().shape)\n",
    "\n",
    "\t# NRMSE\n",
    "\ttry:\n",
    "\t\trmse_pred = normalized_root_mse(im_gt, im_pred)\n",
    "\texcept:\n",
    "\t\trmse_pred = float('nan')\n",
    "\n",
    "\t# PSNR\n",
    "\ttry:\n",
    "\t\tpsnr_pred = peak_signal_noise_ratio(im_gt, im_pred)\n",
    "\texcept:\n",
    "\t\tpsnr_pred = float('nan')\n",
    "\t\t#psnr_pred = psnr(im_gt, im_pred)\n",
    "\t\t#print('use psnr')\n",
    "\t\n",
    "\t# ssim\n",
    "\ttry:\n",
    "\t\tssim_pred = structural_similarity(im_gt, im_pred)\n",
    "\t\tscore_ismrm = sum((np.abs(im_gt.flatten()-im_pred.flatten())<0.1)*mask)/(sum(mask)+0.0)*10000\n",
    "\texcept:\n",
    "\t\tssim_pred = float('nan')\n",
    "\t\tscore_ismrm = float('nan')\n",
    "        \n",
    "\treturn {'rmse':rmse_pred,'psnr':psnr_pred,'ssim':ssim_pred,'score_ismrm':score_ismrm}\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Conv2D, Conv2DTranspose, BatchNormalization, Convolution2D, MaxPooling2D, UpSampling2D, Dense, concatenate\n",
    "from keras.layers import Add as keras_add\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_absolute_error, mean_squared_error\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# clean up\n",
    "def clearKerasMemory():\n",
    "    K.clear_session()\n",
    "\n",
    "# use part of memory\n",
    "def setKerasMemory(limit=0.3):\n",
    "    from tensorflow.compat.v1 import ConfigProto as tf_ConfigProto\n",
    "    from tensorflow.compat.v1 import Session as tf_Session\n",
    "    from tensorflow.python.keras.backend import set_session\n",
    "    config = tf_ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = limit\n",
    "    set_session(tf_Session(config=config))\n",
    "\n",
    "# encoder-deocder\n",
    "def deepEncoderDecoder(num_channel_input=1, num_channel_output=1, \n",
    "\timg_rows=128, img_cols=128, y=np.array([-1,1]), \n",
    "\tlr_init=None, loss_function=mean_absolute_error, metrics_monitor=[PSNRLoss, mean_absolute_error, mean_squared_error],\n",
    "\tnum_poolings = 3, num_conv_per_pooling = 3, \n",
    "\twith_bn=False, verbose=1):\n",
    "\t# BatchNorm\n",
    "\tif with_bn:\n",
    "\t\tlambda_bn = lambda x: BatchNormalization()(x)\n",
    "\telse:\n",
    "\t\tlambda_bn = lambda x: x\n",
    "\t# layers\n",
    "#     For 2D data (e.g. image), \"tf\" assumes (rows, cols, channels) while \"th\" assumes (channels, rows, cols).\n",
    "\tinputs = Input((img_rows, img_cols, num_channel_input))  \n",
    "\tif verbose:\n",
    "\t\tprint(inputs)\n",
    "\t\n",
    "\t#step1\n",
    "\tconv1 = inputs\n",
    "\tnum_channel_first = 32\n",
    "\tfor i in range(num_conv_per_pooling):\n",
    "\t\tconv1 = Conv2D(num_channel_first, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "\t\tconv1 = lambda_bn(conv1)    \n",
    "\tpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\tif verbose:\n",
    "\t\tprint(conv1,pool1)\n",
    "\n",
    "\t# encoder pools\n",
    "\tconvs = [inputs, conv1]\n",
    "\tpools = [inputs, pool1]\n",
    "\tlist_num_features = [num_channel_input, num_channel_first]\n",
    "\tfor i in range(1, num_poolings):\n",
    "\t\t#step2\t\n",
    "\t\tconv_encoder = pools[-1]\n",
    "\t\tnum_channel = num_channel_first*(2**(i-1))\n",
    "\t\tfor j in range(num_conv_per_pooling):\n",
    "\t\t\tconv_encoder = Conv2D(num_channel, (3, 3), padding=\"same\", activation=\"relu\")(conv_encoder)\n",
    "\t\t\tconv_encoder = lambda_bn(conv_encoder)    \n",
    "\t\tpool_encoder = MaxPooling2D(pool_size=(2, 2))(conv_encoder)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(conv_encoder,pool_encoder)\n",
    "\t\tpools.append(pool_encoder)\n",
    "\t\tconvs.append(conv_encoder)\n",
    "\t\tlist_num_features.append(num_channel)\n",
    "\n",
    "\t# center connection\n",
    "\tconv_center = Conv2D(list_num_features[-1], (3, 3), padding=\"same\", activation=\"relu\",\n",
    "\t\t\t\t\t   kernel_initializer='zeros',\n",
    "\t\t\t\t\t   bias_initializer='zeros')(pools[-1])     \n",
    "\tconv_center = keras_add()([pools[-1], conv_center])\t\t\t\t   \n",
    "\tconv_decoders = [conv_center]\n",
    "\tif verbose:\n",
    "\t\tprint(conv_center)\n",
    "\n",
    "\t# decoder steps\n",
    "\tfor i in range(1, num_poolings+1):\n",
    "# \t\tprint('decoder', i, convs, pools)\n",
    "# \t\tprint(UpSampling2D(size=(2, 2))(conv_center))\n",
    "# \t\tprint(convs[-i])\n",
    "\t\tup_decoder = concatenate([UpSampling2D(size=(2, 2))(conv_decoders[-1]), convs[-i]])\t\n",
    "\t\tconv_decoder = up_decoder\n",
    "\t\tfor j in range(num_conv_per_pooling):\n",
    "\t\t\tconv_decoder = Conv2D(list_num_features[-i], (3, 3), padding=\"same\", activation=\"relu\")(conv_decoder)\n",
    "\t\t\tconv_decoder = lambda_bn(conv_decoder)     \n",
    "\t\tconv_decoders.append(conv_decoder)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(conv_decoder,up_decoder)        \n",
    "\n",
    "\t# output layer\n",
    "\tconv_decoder = conv_decoders[-1]\n",
    "\tif max(abs(y))<=1:\n",
    "\t\tif min(np.array(y).flatten())<0:\n",
    "#         tanh -1~+1\n",
    "\t\t\tconv_output = Conv2D(num_channel_output, (1, 1), padding=\"same\", activation=\"tanh\")(conv_decoder)\n",
    "\t\t\tprint('use tanh activation')\n",
    "\t\telse:\n",
    "\t\t\tconv_output = Conv2D(num_channel_output, (1, 1), padding=\"same\", activation='sigmoid')(conv_decoder)    \n",
    "\t\t\tprint('use sigmoid activation')\n",
    "\telse:\n",
    "\t\tconv_output = Conv2D(num_channel_output, (1, 1), padding=\"same\", activation='linear')(conv_decoder)    \n",
    "\t\tprint('use linear activation')\n",
    "\tif verbose:\n",
    "\t\tprint(conv_output)\n",
    "\t\n",
    "\t# model\n",
    "\tmodel = Model(outputs=conv_output, inputs=inputs)\n",
    "\tif verbose:\n",
    "\t\tprint(model)\n",
    "\t\n",
    "\t# fit\n",
    "\tif lr_init is not None:\n",
    "\t\toptimizer = Adam(lr=lr_init)#,0.001 rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\telse:\n",
    "\t\toptimizer = Adam()\n",
    "\tmodel.compile(loss=loss_function, optimizer=optimizer, metrics=metrics_monitor)\n",
    "\t\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will augment data with 0 augmentations\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "augmentation\n",
    "'''\n",
    "list_augments = []\n",
    "num_augment_flipxy = 2\n",
    "num_augment_flipx = 2\n",
    "num_augment_flipy = 2\n",
    "num_augment_shiftx = 1\n",
    "num_augment_shifty = 1\n",
    "for flipxy in range(num_augment_flipxy):\n",
    "\tfor flipx in range(num_augment_flipx):\n",
    "\t\tfor flipy in range(num_augment_flipy):\n",
    "\t\t\tfor shiftx in range(num_augment_shiftx):\n",
    "\t\t\t\tfor shifty in range(num_augment_shifty):\n",
    "\t\t\t\t\taugment={'flipxy':flipxy,'flipx':flipx,'flipy':flipy,'shiftx':shiftx,'shifty':shifty}\n",
    "\t\t\t\t\tlist_augments.append(augment)\n",
    "list_augments = []\n",
    "num_augment=len(list_augments)\n",
    "print('will augment data with {0} augmentations'.format(num_augment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 357.973\n",
      "qoffset_y       : -356.3542\n",
      "qoffset_z       : -139.521\n",
      "srow_x          : [ -2.08626  -0.        0.      357.973  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.3542 ]\n",
      "srow_z          : [   0.          0.          2.031246 -139.521   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC021_01/mr_nifti/t1_mask_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float64\n",
      "bitpix          : 64\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 357.973\n",
      "qoffset_y       : -356.3542\n",
      "qoffset_z       : -139.521\n",
      "srow_x          : [ -2.08626  -0.        0.      357.973  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.3542 ]\n",
      "srow_z          : [   0.          0.          2.031246 -139.521   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC021_01/pet_nifti/3600-180_OP.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint8\n",
      "bitpix          : 8\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 357.973\n",
      "qoffset_y       : -356.3542\n",
      "qoffset_z       : -139.521\n",
      "srow_x          : [ -2.08626  -0.        0.      357.973  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.3542 ]\n",
      "srow_z          : [   0.          0.          2.031246 -139.521   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC021_01/mr_nifti/t1_img_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 16348\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.       2.08626  2.08626  2.031254 0.       0.       0.       0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 31\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 359.6997\n",
      "qoffset_y       : -356.3537\n",
      "qoffset_z       : -139.52124\n",
      "srow_x          : [   2.08626    0.         0.      -355.8875 ]\n",
      "srow_y          : [   0.         2.08626    0.      -356.3537 ]\n",
      "srow_z          : [   0.          0.          2.031254 -139.52124 ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC021_01/pet_nifti/gt_recon.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -158.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -158.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC010/mr_nifti/t1_mask_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float64\n",
      "bitpix          : 64\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -158.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -158.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC010/pet_nifti/3600-180_OP.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint8\n",
      "bitpix          : 8\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -158.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -158.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC010/mr_nifti/t1_img_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 16348\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.       2.08626  2.08626  2.031254 0.       0.       0.       0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 30\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 359.46457\n",
      "qoffset_y       : -356.49362\n",
      "qoffset_z       : -158.52823\n",
      "srow_x          : [   2.08626    0.         0.      -356.12265]\n",
      "srow_y          : [   0.         2.08626    0.      -356.49362]\n",
      "srow_z          : [   0.          0.          2.031254 -158.52823 ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC010/pet_nifti/gt_recon.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -128.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -128.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC011_090518/mr_nifti/t1_mask_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float64\n",
      "bitpix          : 64\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -128.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -128.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC011_090518/pet_nifti/3600-180_OP.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint8\n",
      "bitpix          : 8\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.        2.08626   2.08626   2.031246  0.        0.        0.\n",
      "  0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'Warped image using NiftyReg (reg_resample)'\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 358.208\n",
      "qoffset_y       : -356.49417\n",
      "qoffset_z       : -128.528\n",
      "srow_x          : [ -2.08626  -0.        0.      358.208  ]\n",
      "srow_y          : [  -0.         2.08626   -0.      -356.49417]\n",
      "srow_z          : [   0.          0.          2.031246 -128.528   ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC011_090518/mr_nifti/t1_img_registered.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 16348\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 344 344 127   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.       2.08626  2.08626  2.031254 0.       0.       0.       0.      ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 16\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 359.46457\n",
      "qoffset_y       : -356.49362\n",
      "qoffset_z       : -128.52823\n",
      "srow_x          : [   2.08626    0.         0.      -356.12265]\n",
      "srow_y          : [   0.         2.08626    0.      -356.49362]\n",
      "srow_z          : [   0.          0.          2.031254 -128.52823 ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "SHAPE (344, 344, 127)\n",
      "loaded from /autofs/space/celer_001/users/leila/data/pbr28/PBRKOA_HC011_090518/pet_nifti/gt_recon.nii.gz, data size (127, 344, 344, 1) (sample, x, y, channel)\n",
      "setup parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 15:05:26.209606: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 15:05:26.543071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543220: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-15 15:05:26.543453: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-15 15:05:26.697013: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 344, 344, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 344, 344, 32), dtype=tf.float32, name=None), name='batch_normalization_2/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_2'\") KerasTensor(type_spec=TensorSpec(shape=(None, 172, 172, 32), dtype=tf.float32, name=None), name='max_pooling2d/MaxPool:0', description=\"created by layer 'max_pooling2d'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 172, 172, 32), dtype=tf.float32, name=None), name='batch_normalization_5/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_5'\") KerasTensor(type_spec=TensorSpec(shape=(None, 86, 86, 32), dtype=tf.float32, name=None), name='max_pooling2d_1/MaxPool:0', description=\"created by layer 'max_pooling2d_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 86, 86, 64), dtype=tf.float32, name=None), name='batch_normalization_8/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_8'\") KerasTensor(type_spec=TensorSpec(shape=(None, 43, 43, 64), dtype=tf.float32, name=None), name='max_pooling2d_2/MaxPool:0', description=\"created by layer 'max_pooling2d_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43, 43, 64), dtype=tf.float32, name=None), name='add/add:0', description=\"created by layer 'add'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 86, 86, 64), dtype=tf.float32, name=None), name='batch_normalization_11/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_11'\") KerasTensor(type_spec=TensorSpec(shape=(None, 86, 86, 128), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 172, 172, 32), dtype=tf.float32, name=None), name='batch_normalization_14/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_14'\") KerasTensor(type_spec=TensorSpec(shape=(None, 172, 172, 96), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 344, 344, 32), dtype=tf.float32, name=None), name='batch_normalization_17/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_17'\") KerasTensor(type_spec=TensorSpec(shape=(None, 344, 344, 64), dtype=tf.float32, name=None), name='concatenate_2/concat:0', description=\"created by layer 'concatenate_2'\")\n",
      "use tanh activation\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 344, 344, 1), dtype=tf.float32, name=None), name='conv2d_19/Tanh:0', description=\"created by layer 'conv2d_19'\")\n",
      "<keras.engine.functional.Functional object at 0x7f11d00c3bb0>\n",
      "train model: /autofs/space/celer_001/users/leila/ckpt/test_3_samp_5_epoch.ckpt\n",
      "parameter count: 410017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/celer_001/users/leila/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_dataset_train = generate_file_list_object(FILTERED_PATIENT_LIST_WITH_GT , FINAL_DATA_PATH_FOR_MODEL)\n",
    "num_dataset_train = len(list_dataset_train)    \n",
    "list_data_train_input = []\n",
    "\n",
    "\n",
    "for index_data in range(num_dataset_train):\n",
    "\t# directory\n",
    "\t# headmask = prepare_data_from_nifti(os.path.dirname(list_dataset_train[index_data]['input'][1])+'/headmask_inv.nii', list_augments, False)\n",
    "\theadmask = prepare_data_from_nifti(os.path.dirname(list_dataset_train[index_data]['input'][1])+'/t1_mask_registered.nii.gz', list_augments, False)\n",
    "\n",
    "\tlist_data_train_input = []\n",
    "\tfor path_train_input in list_dataset_train[index_data]['input']:\n",
    "\t\t# load data\n",
    "\t\tdata_train_input = prepare_data_from_nifti(path_train_input, list_augments)\n",
    "\t\tdata_train_input = np.multiply(data_train_input, headmask) # data_train_input \n",
    "\t\tlist_data_train_input.append(data_train_input)\n",
    "\tdata_train_input = np.concatenate(list_data_train_input, axis=-1)\n",
    "\t\n",
    "\t\n",
    "\t# load data ground truth\n",
    "\tpath_train_gt = list_dataset_train[index_data]['gt']\n",
    "\tdata_train_gt = prepare_data_from_nifti(path_train_gt, list_augments)\n",
    "\n",
    "'''\n",
    "setup parameters\n",
    "'''\n",
    "\n",
    "\n",
    "# related to model\n",
    "num_poolings = 3\n",
    "num_conv_per_pooling = 3\n",
    "# related to training\n",
    "lr_init = 0.0002\n",
    "num_epoch = 100\n",
    "ratio_validation = 0.1\n",
    "validation_split = 0.1\n",
    "batch_size = 4\n",
    "y_range = [-0.5,0.5]\n",
    "# default settings\n",
    "num_channel_input = data_train_input.shape[-1]\n",
    "num_channel_output = data_train_gt.shape[-1]\n",
    "img_rows = data_train_input.shape[1]\n",
    "img_cols = data_train_gt.shape[1]\n",
    "keras_memory = 0.4\n",
    "keras_backend = 'tf'\n",
    "with_batch_norm = True\n",
    "print('setup parameters')\n",
    "\n",
    "\n",
    "'''\n",
    "init model\n",
    "'''\n",
    "callback_checkpoint = ModelCheckpoint(CHECKPOINT_PATH, \n",
    "\t\t\t\t\t\t\t\tmonitor='val_loss', \n",
    "\t\t\t\t\t\t\t\tsave_best_only=True)\n",
    "setKerasMemory(keras_memory)\n",
    "model = deepEncoderDecoder(num_channel_input = num_channel_input,\n",
    "\t\t\t\t\t\tnum_channel_output = num_channel_output,\n",
    "\t\t\t\t\t\timg_rows = img_rows,\n",
    "\t\t\t\t\t\timg_cols = img_cols,\n",
    "\t\t\t\t\t\tlr_init = lr_init, \n",
    "\t\t\t\t\t\tnum_poolings = num_poolings, \n",
    "\t\t\t\t\t\tnum_conv_per_pooling = num_conv_per_pooling, \n",
    "\t\t\t\t\t\twith_bn = with_batch_norm, verbose=1)\n",
    "print('train model:', CHECKPOINT_PATH)\n",
    "print('parameter count:', model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/autofs/space/celer_001/users/leila/ckpt/test_3_samp_5_epoch.ckpt/saved_model.pb') as f:\n",
    "#     model = tf.keras.models.load_model(f)\n",
    "\n",
    "model.load_weights(\"/autofs/space/celer_001/users/leila/ckpt/weights-001-0.0319.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "\t'Generates data for Keras'\n",
    "\tdef __init__(self, dim_x = 512, dim_y = 512, dim_z = 6, dim_output = 1, \n",
    "\t\t\t\tbatch_size = 2, shuffle = True, verbose = 1,\n",
    "\t\t\t\tscale_data = 1.0, scale_baseline = 1.0):\n",
    "\t\t'Initialization'\n",
    "\t\tself.dim_x = dim_x\n",
    "\t\tself.dim_y = dim_y\n",
    "\t\tself.dim_z = dim_z\n",
    "\t\tself.dim_output = dim_output\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.shuffle = shuffle\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.scale_data = scale_data\n",
    "\t\tself.scale_baseline = scale_baseline\n",
    "\n",
    "\tdef generate(self, dir_sample, list_IDs):\n",
    "\t\t'Generates batches of samples'\n",
    "\t\t# Infinite loop\n",
    "\t\twhile 1:\n",
    "\t\t\t# Generate order of exploration of dataset\n",
    "\t\t\tindexes = self.__get_exploration_order(list_IDs)\n",
    "\t\t\tif self.verbose>0:\n",
    "\t\t\t\tprint('indexes:', indexes)\n",
    "\t\t\t# Generate batches\n",
    "\t\t\timax = int(len(indexes)/self.batch_size)\n",
    "\t\t\tif self.verbose>0:            \n",
    "\t\t\t\tprint('imax:', imax)\n",
    "\t\t\tfor i in range(imax):\n",
    "\t\t\t\t# Find list of IDs\n",
    "\t\t\t\tlist_IDs_temp = [list_IDs[k] for k in indexes[i*self.batch_size:(i+1)*self.batch_size]]\n",
    "\t\t\t\tif self.verbose>0:\n",
    "\t\t\t\t\tprint('list_IDs_temp:', list_IDs_temp)\n",
    "\t\t\t\t# Generate data\n",
    "\t\t\t\tX, Y = self.__data_generation(dir_sample, list_IDs_temp)\n",
    "\t\t\t\tif self.verbose>0:                \n",
    "\t\t\t\t\tprint('generated dataset size:', X.shape, Y.shape)\n",
    "\n",
    "\t\t\t\tyield X, Y\n",
    "\n",
    "\tdef __get_exploration_order(self, list_IDs):\n",
    "\t\t'Generates order of exploration'\n",
    "\t\t# Find exploration order\n",
    "\t\tindexes = np.arange(len(list_IDs))\n",
    "\t\tif self.shuffle == True:\n",
    "\t\t\tnp.random.shuffle(indexes)\n",
    "\t\treturn indexes\n",
    "\n",
    "\tdef __data_generation(self, dir_sample, list_IDs_temp, ext_data = 'npz'):\n",
    "\t\t'Generates data of batch_size samples' # X : (n_samples, v_size, v_size, v_size, n_channels)\n",
    "\t\t# Initialization\n",
    "\t\tX = np.empty((self.batch_size, self.dim_x, self.dim_y, self.dim_z, 1))\n",
    "\t\tY = np.empty((self.batch_size, self.dim_x, self.dim_y, self.dim_output, 1))\n",
    "\n",
    "\t\t# Generate data\n",
    "\t\tfor i, ID in enumerate(list_IDs_temp):\n",
    "\t\t\t# Store volume\n",
    "\t\t\tdata_load = np.load(os.path.join(dir_sample, '{0}.{1}'.format(ID,ext_data)))\n",
    "\t\t\tX[i, :, :, :, 0] = data_load['input']\n",
    "\t\t\tY[i, :, :, :, 0] = data_load['output'] \n",
    "\t\tX = X[:,:,:,:,0]\n",
    "\t\tY = Y[:,:,:,:,0]        \n",
    "\t\tX = X * self.scale_data\n",
    "\t\tY = Y * self.scale_data\n",
    "\t\tY = Y - self.scale_baseline * X[:,:,:,0:1]   \n",
    "\t\tprint(X.shape, Y.shape)   \n",
    "\t\treturn X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator parameters: {'dim_x': 344, 'dim_y': 344, 'dim_z': 2, 'dim_output': 1, 'batch_size': 4, 'shuffle': False, 'verbose': 0, 'scale_data': 100.0, 'scale_baseline': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# details inside generator\n",
    "params_generator = {'dim_x': img_rows,\n",
    "\t\t  'dim_y': img_cols,\n",
    "\t\t  'dim_z': num_channel_input,\n",
    "\t\t  'dim_output': num_channel_output,\n",
    "\t\t  'batch_size': 4,\n",
    "\t\t  'shuffle': False,\n",
    "\t\t  'verbose': 0,\n",
    "\t\t  'scale_data': 100.,\n",
    "\t\t  'scale_baseline': 1.0}\n",
    "print('generator parameters:', params_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/autofs/space/celer_001/users/leila/pbr28-low-high-count/model-results\n",
      "train on 2743 samples and validation on 304 samples\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "setup train and val generator\n",
    "'''\n",
    "!pwd\n",
    "dir_samples = '../../data/data_sample/'\n",
    "validation_split = 0.1\n",
    "ext_data = 'npz'\n",
    "index_sample_total = len([x for x in os.listdir(dir_samples) if x.endswith(ext_data)])\n",
    "list_indexes_train = np.random.permutation(index_sample_total)\n",
    "if validation_split>1:\n",
    "\tlist_indexes_val = list_indexes_train[-validation_split:].tolist()\n",
    "\tlist_indexes_train = list_indexes_train[:int(index_sample_total-validation_split)].tolist()    \n",
    "else:\n",
    "\tlist_indexes_val = list_indexes_train[-int(index_sample_total*validation_split):].tolist()\n",
    "\tlist_indexes_train = list_indexes_train[:int(index_sample_total*(1-validation_split))].tolist()\n",
    "print('train on {0} samples and validation on {1} samples'.format(\n",
    "\t\tlen(list_indexes_train), len(list_indexes_val)))\n",
    "training_generator = DataGenerator(**params_generator).generate(dir_samples, list_indexes_train)\n",
    "validation_generator = DataGenerator(**params_generator).generate(dir_samples, list_indexes_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  1/100 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch/ipykernel_3639511/1026782263.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  prediction = model.predict_generator(validation_generator, verbose=1, steps=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  2/100 [..............................] - ETA: 8s (4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  3/100 [..............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  4/100 [>.............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  5/100 [>.............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  6/100 [>.............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  7/100 [=>............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  8/100 [=>............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "  9/100 [=>............................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 10/100 [==>...........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 11/100 [==>...........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 12/100 [==>...........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 13/100 [==>...........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 14/100 [===>..........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 15/100 [===>..........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 16/100 [===>..........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 17/100 [====>.........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 18/100 [====>.........................] - ETA: 7s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 19/100 [====>.........................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 20/100 [=====>........................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 21/100 [=====>........................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 22/100 [=====>........................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 23/100 [=====>........................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 24/100 [======>.......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 25/100 [======>.......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 26/100 [======>.......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 27/100 [=======>......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 28/100 [=======>......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 29/100 [=======>......................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 30/100 [========>.....................] - ETA: 6s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 31/100 [========>.....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 32/100 [========>.....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 33/100 [========>.....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 34/100 [=========>....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 35/100 [=========>....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 36/100 [=========>....................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 37/100 [==========>...................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 38/100 [==========>...................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 39/100 [==========>...................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 40/100 [===========>..................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 41/100 [===========>..................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 42/100 [===========>..................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 43/100 [===========>..................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 44/100 [============>.................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 45/100 [============>.................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 46/100 [============>.................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 47/100 [=============>................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 48/100 [=============>................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 49/100 [=============>................] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 50/100 [==============>...............] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 51/100 [==============>...............] - ETA: 5s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 52/100 [==============>...............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 53/100 [==============>...............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 54/100 [===============>..............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 55/100 [===============>..............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 56/100 [===============>..............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 57/100 [================>.............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 58/100 [================>.............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 59/100 [================>.............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 60/100 [=================>............] - ETA: 4s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 61/100 [=================>............] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 62/100 [=================>............] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 63/100 [=================>............] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 64/100 [==================>...........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 65/100 [==================>...........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 66/100 [==================>...........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 67/100 [===================>..........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 68/100 [===================>..........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 69/100 [===================>..........] - ETA: 3s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 70/100 [====================>.........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 71/100 [====================>.........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 72/100 [====================>.........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 73/100 [====================>.........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 74/100 [=====================>........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 75/100 [=====================>........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 76/100 [=====================>........] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 77/100 [======================>.......] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 78/100 [======================>.......] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 79/100 [======================>.......] - ETA: 2s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 80/100 [=======================>......] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 81/100 [=======================>......] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 82/100 [=======================>......] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 83/100 [=======================>......] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 84/100 [========================>.....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 85/100 [========================>.....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 86/100 [========================>.....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 87/100 [=========================>....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 88/100 [=========================>....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 89/100 [=========================>....] - ETA: 1s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 90/100 [==========================>...] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 91/100 [==========================>...] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 92/100 [==========================>...] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 93/100 [==========================>...] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 94/100 [===========================>..] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 95/100 [===========================>..] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 96/100 [===========================>..] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 97/100 [============================>.] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 98/100 [============================>.] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      " 99/100 [============================>.] - ETA: 0s(4, 344, 344, 2) (4, 344, 344, 1)\n",
      "100/100 [==============================] - 9s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(validation_generator, verbose=1, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/autofs/space/celer_001/users/leila/pbr28-low-high-count/model-results/visualize-output.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bceler.nmr.mgh.harvard.edu/autofs/space/celer_001/users/leila/pbr28-low-high-count/model-results/visualize-output.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m training_generator\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "training_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6dd644061696395b513294d8c64a2fd82baaf51241526334e93af3b2c2ccabf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
